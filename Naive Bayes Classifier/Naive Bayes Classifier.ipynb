{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy, pandas and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import Counter #added python standard library: collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bins(df,nobins=10,bintype='equal-width'):\n",
    "    cdf=df.copy()\n",
    "    numerical_cdf=df.copy()\n",
    "    for i in ['ID','CLASS']:\n",
    "        if i in cdf: numerical_cdf=numerical_cdf.drop([i], axis=1)\n",
    "    numerical_cdf=numerical_cdf.select_dtypes(include=['number'])\n",
    "    binfunc=[pd.cut,pd.qcut]\n",
    "    binning={}\n",
    "\n",
    "    if bintype==\"equal-width\": a=binfunc[0]\n",
    "    elif bintype==\"equal-size\": a=binfunc[1]\n",
    "    else: a=binfunc[0]\n",
    "\n",
    "    for i in numerical_cdf:\n",
    "        res,bins=a(cdf[i],nobins,retbins=True,labels=False,duplicates='drop')\n",
    "        bins[0]=-np.inf\n",
    "        bins[-1]=np.inf\n",
    "        binning[i]=bins\n",
    "        cdf[i]=res.astype('category')\n",
    "    return cdf,binning\n",
    "\n",
    "def apply_bins(df,binning):\n",
    "    cdf=df.copy()\n",
    "    numerical_cdf=df.copy()\n",
    "    for i in ['ID','CLASS']:\n",
    "        numerical_cdf=numerical_cdf.drop([i], axis=1)\n",
    "    numerical_cdf=numerical_cdf.select_dtypes(include=['number'])\n",
    "\n",
    "    for i in numerical_cdf:\n",
    "        bins=binning[i]\n",
    "        res,bins=pd.cut(cdf[i],bins,retbins=True,labels=False,duplicates='drop')\n",
    "        cdf[i]=res.astype('category')\n",
    "    return cdf\n",
    "\n",
    "\n",
    "def create_imputation(anneal_train_df):\n",
    "    anneal_train_df_copy = anneal_train_df.copy()\n",
    "    imputation_template = {}\n",
    "    \n",
    "    df_cols = anneal_train_df_copy.loc[:, ~anneal_train_df_copy.columns.isin(['ID', 'CLASS'])]\n",
    "    numerical_columns = df_cols.select_dtypes(include=['number']).columns\n",
    "    non_numerical_columns = df_cols.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "    anneal_train_df_numerical = anneal_train_df_copy.loc[:, numerical_columns]\n",
    "    for column in anneal_train_df_numerical.columns:\n",
    "        non_missing_col_data = anneal_train_df_numerical.loc[:,column]\n",
    "        if(non_missing_col_data.dropna().shape[0] > 0):\n",
    "            mean_value = non_missing_col_data.mean()\n",
    "        else:\n",
    "            mean_value = 0\n",
    "            \n",
    "        anneal_train_df_copy[column] = anneal_train_df_copy[column].fillna(mean_value)\n",
    "        imputation_template[column] = mean_value\n",
    "\n",
    "    anneal_train_df_categorical = anneal_train_df_copy.loc[:, non_numerical_columns]\n",
    "    for column in anneal_train_df_categorical.columns:\n",
    "        non_missing_col_data = anneal_train_df_categorical[column]\n",
    "        if(non_missing_col_data.dropna().shape[0] > 0):\n",
    "            mode_value = non_missing_col_data.mode()[0]\n",
    "        else:\n",
    "            mode_value = \"\"\n",
    "        \n",
    "        anneal_train_df_copy[column] = anneal_train_df_copy[column].fillna(mode_value)\n",
    "        imputation_template[column] = mode_value\n",
    "            \n",
    "        \n",
    "    return anneal_train_df_copy, imputation_template\n",
    "\n",
    "def apply_imputation(anneal_test_df, imputation):\n",
    "    anneal_test_df_copy = anneal_test_df.copy()\n",
    "    df_cols = anneal_test_df_copy.loc[:, ~anneal_test_df_copy.columns.isin(['ID', 'CLASS'])]\n",
    "    \n",
    "    for column in df_cols.columns:\n",
    "        anneal_test_df_copy[column] = anneal_test_df_copy[column].fillna(imputation[column])\n",
    "\n",
    "    return anneal_test_df_copy\n",
    "    \n",
    "\n",
    "\n",
    "def create_normalization(file_df,normalizationtype):\n",
    "    normalization = {}\n",
    "    new_file_df = file_df.copy()\n",
    "    \n",
    "    if (normalizationtype == \"minmax\"):\n",
    "        for col_name in file_df:\n",
    "            if (col_name != \"ID\" and col_name != \"CLASS\"):\n",
    "                min_col = file_df[col_name].min()\n",
    "                max_col = file_df[col_name].max()\n",
    "                normalization[col_name] = (\"minmax\", min_col,max_col)\n",
    "                new_file_df[col_name] = file_df[col_name].apply(lambda x:(x-min_col)/(max_col-min_col))\n",
    "        \n",
    "    elif (normalizationtype == \"zscore\"):\n",
    "        for col_name in file_df:\n",
    "            if (col_name != \"ID\" and col_name != \"CLASS\"):\n",
    "                mean_col = file_df[col_name].mean()\n",
    "                std_col = file_df[col_name].std()\n",
    "                normalization[col_name] = (\"zscore\", mean_col,std_col)\n",
    "                new_file_df[col_name] = file_df[col_name].apply(lambda x:(x-mean_col)/std_col)\n",
    "    \n",
    "    return (new_file_df, normalization)\n",
    "\n",
    "def apply_normalization(file_df,normalization):\n",
    "    \n",
    "    new_file_df = file_df.copy()\n",
    "    \n",
    "    for col_name in normalization:\n",
    "        \n",
    "        if (normalization[col_name][0] == \"minmax\"):\n",
    "            min_col = normalization[col_name][1]\n",
    "            max_col = normalization[col_name][2]\n",
    "            new_file_df[col_name] = file_df[col_name].apply(lambda x:(x-min_col)/(max_col-min_col))\n",
    "        \n",
    "        elif (normalization[col_name][0] == \"zscore\"):\n",
    "            mean_col = normalization[col_name][1]\n",
    "            std_col = normalization[col_name][2]\n",
    "            new_file_df[col_name] = file_df[col_name].apply(lambda x:(x-mean_col)/std_col)\n",
    "    \n",
    "    return (new_file_df)\n",
    "\n",
    "\n",
    "def create_one_hot(df_file):\n",
    "    one_hot_df = df_file.copy()\n",
    "    one_hot_dict = {}\n",
    "    for col_name in df_file:\n",
    "        if (col_name != \"CLASS\" and col_name != \"ID\"):\n",
    "            col = df_file[col_name]\n",
    "            col_hot = pd.get_dummies(col,prefix = col_name, dtype = \"float\")\n",
    "            one_hot_df = pd.concat([one_hot_df, col_hot], axis=1)\n",
    "            one_hot_df = one_hot_df.drop(col_name, axis=1)\n",
    "            one_hot_dict[col_name] = set(col)\n",
    "    \n",
    "    return (one_hot_df,one_hot_dict)\n",
    "\n",
    "\n",
    "def apply_one_hot(df_file, one_hot): \n",
    "    \n",
    "    #Gives zero column for categories who doesnt exist on the test df\n",
    "    \n",
    "    hot_df_file = df_file.copy()\n",
    "\n",
    "    for col_name, col_unique_values  in one_hot.items():\n",
    "        col = df_file[col_name]\n",
    "        cat = col.astype(pd.api.types.CategoricalDtype(categories= col_unique_values))\n",
    "        col_hot = pd.get_dummies(cat, prefix = col_name, dtype = \"float\")\n",
    "        hot_df_file = pd.concat([hot_df_file, col_hot], axis=1)\n",
    "        hot_df_file = hot_df_file.drop(col_name, axis=1)\n",
    "                                    \n",
    "    return (hot_df_file)\n",
    "\n",
    "def accuracy(pred_df, label):\n",
    "    \n",
    "    score = 0\n",
    "    for row in range(len(pred_df)):\n",
    "        pred_row = pred_df.iloc[row,:]\n",
    "        if pred_row.idxmax() == label[row]:\n",
    "            score = score + 1\n",
    "            \n",
    "    return (score/len(pred_df))\n",
    "\n",
    "\n",
    "def brier_score(df_file, correctlabels):\n",
    "    correctlabels_df = pd.DataFrame(correctlabels)\n",
    "    correctlabels_df = correctlabels_df.astype(pd.api.types.CategoricalDtype(categories= df_file.columns))\n",
    "    correctlabels_hot = pd.get_dummies(correctlabels_df)\n",
    "\n",
    "    score = []\n",
    "    for row in range(np.size(df_file,0)):\n",
    "        for col in range(np.size(df_file,1)):\n",
    "            score_each_element = df_file.iloc[row,col]- correctlabels_hot.iloc[row,col]\n",
    "            score_each_element = np.power(score_each_element, 2)\n",
    "            score.append(score_each_element)\n",
    "\n",
    "    brier_score = sum(score)/np.size(df_file,0)\n",
    "    \n",
    "    return(brier_score)\n",
    "\n",
    "\n",
    "def TP_AND_FP(predictions_decoded, correct_labels, positive_label):\n",
    "    \"\"\"Takes decoded predictions and labels\"\"\"\n",
    " \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for prediction, label in zip(predictions_decoded.tolist(), correct_labels):\n",
    "        if prediction == 1:\n",
    "            if(label == positive_label):\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "           \n",
    "    num_positives = sum([1 for label in correct_labels if label == positive_label])\n",
    "    num_negatives = sum([1 for label in correct_labels if label != positive_label])\n",
    "   \n",
    "    return true_positives/num_positives, false_positives/num_negatives\n",
    "\n",
    "def auc_calc_np(tp_fp_dict):\n",
    "    unique_values = sorted( list(set([value for key, value in tp_fp_dict.items()])) )\n",
    "    tpr = np.array([value[0] for value in unique_values])\n",
    "    fpr = np.array([value[1] for value in unique_values])\n",
    " \n",
    "    area = np.trapz(tpr, fpr)\n",
    "    return area\n",
    "\n",
    "def binary_auc(predictions, correct_labels, positive_label='A', num_thresholds=10):\n",
    "    \"\"\"preprocesses the data into binary predictions, positives vs rest(negatives)\"\"\"\n",
    "    tp_fp_dict = {}\n",
    "    without_boundaries = np.linspace(0, 1, num_thresholds)\n",
    "    for threshold in without_boundaries:\n",
    "        predictions_copy = predictions.copy()\n",
    "        binary_positive_pred = predictions_copy.apply(lambda x: 1 if x[positive_label] >= threshold else 0, axis=1)\n",
    " \n",
    "        tp_fp_dict[threshold] = TP_AND_FP(binary_positive_pred, correct_labels, positive_label)\n",
    " \n",
    "    return auc_calc_np(tp_fp_dict)\n",
    " \n",
    "def auc(predictions, correct_labels, num_thresholds=100):\n",
    "    correct_labels = correct_labels.tolist() \n",
    "    label_frequencies = {x:correct_labels.count(x)/len(correct_labels) for x in correct_labels}\n",
    " \n",
    "    total_auc = 0\n",
    "    for label, label_frequency in label_frequencies.items():\n",
    "        auc = binary_auc(predictions, correct_labels, positive_label=label, num_thresholds=num_thresholds)\n",
    "        total_auc += auc*label_frequency\n",
    " \n",
    "    return total_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the class NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.binning=None\n",
    "        self.class_priors=None\n",
    "        self.feature_class_value_counts=None\n",
    "        self.feature_class_counts=None\n",
    "\n",
    "    def fit(self,data_frame,nobins=10,bintype=\"equal_width\"):\n",
    "        data_frame_discrete,self.binning=create_bins(data_frame,nobins,bintype)\n",
    "        self.class_priors={}\n",
    "        self.feature_class_value_counts={}\n",
    "        self.feature_class_counts={}\n",
    "\n",
    "        #calculates the class priors\n",
    "        #and saves the results in self.class_priors\n",
    "        for key,value in data_frame_discrete.groupby(\"CLASS\")[\"CLASS\"]:\n",
    "            self.class_priors[key]=value.count()/data_frame_discrete[\"CLASS\"].size\n",
    "\n",
    "\n",
    "        for feature in data_frame_discrete.loc[:, ~data_frame_discrete.columns.isin([\"ID\",'CLASS'])]:\n",
    "            feature_map={}\n",
    "\n",
    "            #calculates the number of training instances with a specific combination of class and feature value\n",
    "            #and saves the results in self.feature_class_value_counts\n",
    "            for key,value in data_frame_discrete.groupby([feature,\"CLASS\"])[feature]:\n",
    "                feature_map[key]=value.count()\n",
    "            self.feature_class_value_counts[feature]=feature_map\n",
    "\n",
    "            #calculates the number of training instances with a specific class value and any value for the feature\n",
    "            #and saves the results in self.feature_class_counts\n",
    "            for key,value in data_frame_discrete.groupby([\"CLASS\"])[feature]:\n",
    "                self.feature_class_counts[(feature,key)]=value.count()\n",
    "\n",
    "        return\n",
    "\n",
    "    def predict(self, data_frame):\n",
    "        #applys discretization\n",
    "        data_frame_discrete=apply_bins(data_frame,self.binning)\n",
    "        posterior_matrix=[]\n",
    "        for index in range(len(data_frame_discrete)):\n",
    "            posterior_list=[]\n",
    "            likelihood={}\n",
    "            conditional_statement=True\n",
    "            evidence=0\n",
    "\n",
    "            for class_value in sorted(data_frame_discrete.CLASS.unique()):\n",
    "                likelihood_class=0\n",
    "\n",
    "                for feature in data_frame_discrete.loc[:, ~data_frame_discrete.columns.isin([\"ID\",'CLASS'])]:\n",
    "                    value=data_frame_discrete.loc[index,feature]\n",
    "\n",
    "                    #calculates the relative frequency of the observed feature value given the class\n",
    "                    if (value,class_value) in self.feature_class_value_counts[feature].keys():\n",
    "                        likelihood_feature=(self.feature_class_value_counts[feature][(value,class_value)])/(self.feature_class_counts[feature,class_value])\n",
    "\n",
    "                    # if the frequency of the observed feature value given the class is missing in\n",
    "                    # the training set the likelihood is set to zero (missing = zero)\n",
    "                    else:\n",
    "                        likelihood_class=0\n",
    "                        break\n",
    "\n",
    "                    #calculates the likelihood iteratively\n",
    "                    likelihood_class+=np.log(likelihood_feature)\n",
    "\n",
    "                likelihood[class_value]=likelihood_class\n",
    "                \n",
    "                #calculates the evidence iteratively\n",
    "                if likelihood_class!=0:\n",
    "                    conditional_statement=False\n",
    "                    evidence+=np.exp(likelihood_class+np.log(self.class_priors[class_value]))\n",
    "\n",
    "            #calculates the probabilities for the classes given the observed data point\n",
    "            for class_value in sorted(data_frame_discrete.CLASS.unique()):\n",
    "\n",
    "                #If the sum of non-normalized probabilities is zero the probability(posterior) is set to the class prior\n",
    "                if conditional_statement:\n",
    "                    posterior=self.class_priors[class_value]\n",
    "\n",
    "                #if the likelihood is zero then the posterior is zero\n",
    "                elif likelihood[class_value]==0:\n",
    "                    posterior=0\n",
    "\n",
    "                #calculates the posterior for the other cases\n",
    "                else:\n",
    "                    posterior=np.exp(likelihood[class_value]+np.log(self.class_priors[class_value])-np.log(evidence))\n",
    "\n",
    "                posterior_list+=[posterior]\n",
    "\n",
    "            posterior_matrix+=[posterior_list]\n",
    "\n",
    "        data_frame_predict=pd.DataFrame(posterior_matrix, columns = sorted(data_frame_discrete.CLASS.unique()))\n",
    "\n",
    "        return  data_frame_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (3, 'equal-width'): 0.13 s.\n",
      "Testing time (3, 'equal-width'): 1.25 s.\n",
      "Training time (3, 'equal-size'): 0.12 s.\n",
      "Testing time (3, 'equal-size'): 1.38 s.\n",
      "Training time (5, 'equal-width'): 0.15 s.\n",
      "Testing time (5, 'equal-width'): 1.36 s.\n",
      "Training time (5, 'equal-size'): 0.14 s.\n",
      "Testing time (5, 'equal-size'): 1.07 s.\n",
      "Training time (10, 'equal-width'): 0.16 s.\n",
      "Testing time (10, 'equal-width'): 1.08 s.\n",
      "Training time (10, 'equal-size'): 0.19 s.\n",
      "Testing time (10, 'equal-size'): 1.15 s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Brier score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>equal-width</th>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.622116</td>\n",
       "      <td>0.724856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal-size</th>\n",
       "      <td>0.607477</td>\n",
       "      <td>0.554782</td>\n",
       "      <td>0.780478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>equal-width</th>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.551101</td>\n",
       "      <td>0.770186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal-size</th>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.581556</td>\n",
       "      <td>0.792174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>equal-width</th>\n",
       "      <td>0.654206</td>\n",
       "      <td>0.527569</td>\n",
       "      <td>0.809678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal-size</th>\n",
       "      <td>0.588785</td>\n",
       "      <td>0.741668</td>\n",
       "      <td>0.723134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Accuracy  Brier score       AUC\n",
       "3  equal-width  0.616822     0.622116  0.724856\n",
       "   equal-size   0.607477     0.554782  0.780478\n",
       "5  equal-width  0.644860     0.551101  0.770186\n",
       "   equal-size   0.598131     0.581556  0.792174\n",
       "10 equal-width  0.654206     0.527569  0.809678\n",
       "   equal-size   0.588785     0.741668  0.723134"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code (leave this part unchanged, except for if auc is undefined)\n",
    "\n",
    "glass_train_df = pd.read_csv(\"glass_train.txt\")\n",
    "\n",
    "glass_test_df = pd.read_csv(\"glass_test.txt\")\n",
    "\n",
    "nb_model = NaiveBayes()\n",
    "\n",
    "test_labels = glass_test_df[\"CLASS\"]\n",
    "\n",
    "nobins_values = [3,5,10]\n",
    "bintype_values = [\"equal-width\",\"equal-size\"]\n",
    "parameters = [(nobins,bintype) for nobins in nobins_values for bintype in bintype_values]\n",
    "\n",
    "results = np.empty((len(parameters),3))\n",
    "\n",
    "for i in range(len(parameters)):\n",
    "    t0 = time.perf_counter()\n",
    "    nb_model.fit(glass_train_df,nobins=parameters[i][0],bintype=parameters[i][1])\n",
    "    print(\"Training time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    t0 = time.perf_counter()\n",
    "    predictions = nb_model.predict(glass_test_df)\n",
    "    print(\"Testing time {0}: {1:.2f} s.\".format(parameters[i],time.perf_counter()-t0))\n",
    "    results[i] = [accuracy(predictions,test_labels),brier_score(predictions,test_labels),\n",
    "                  auc(predictions,test_labels)] # Assuming that you have defined auc - remove otherwise\n",
    "\n",
    "results = pd.DataFrame(results,index=pd.MultiIndex.from_product([nobins_values,bintype_values]),\n",
    "                       columns=[\"Accuracy\",\"Brier score\",\"AUC\"])\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.85\n",
      "AUC on training set: 0.96\n",
      "Brier score on training set: 0.23\n"
     ]
    }
   ],
   "source": [
    "train_labels = glass_train_df[\"CLASS\"]\n",
    "nb_model.fit(glass_train_df)\n",
    "predictions = nb_model.predict(glass_train_df)\n",
    "print(\"Accuracy on training set: {0:.2f}\".format(accuracy(predictions,train_labels)))\n",
    "print(\"AUC on training set: {0:.2f}\".format(auc(predictions,train_labels)))\n",
    "print(\"Brier score on training set: {0:.2f}\".format(brier_score(predictions,train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on assumptions, things that do not work properly, etc.\n",
    "\n",
    "According to the Naive Bayes theorem. The likelihood of feature values given a class can be divided into products of likelihoods because we assume the features are independent. \n",
    "\n",
    "To avoid underflow. Instead of multiplying each likelihood, used logarithm and exponential to reverse in the posterior. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
